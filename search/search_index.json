{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Podcast Benchmark Documentation","text":"<p>A benchmarking framework for neural decoding from podcast listening data. </p>"},{"location":"#decoding-tasks","title":"Decoding Tasks","text":"<ol> <li>Brain --&gt; perceived word decoding Translate brain signals to perceived words, comparing performance to previously published results.</li> <li>Audio Reconstruction Reconstruct podcast audio envelope from brain signal (Regression)</li> <li>Sentence Onset Detection Classify (binary) segments of brain data as containing the beginning of a sentence or not</li> <li>Content/Non-Content Words Classification (Binary classification)</li> <li>Part of Speech Classification (Multiclass classification)</li> <li>LLM Surprise Predict how likely the perceived word is given it's context (Regression)</li> </ol>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ol> <li>Quickstart - Get up and running quickly</li> <li>Onboarding a New Model - Step-by-step guide to adding your own decoding model</li> <li>Adding a New Task - How to implement custom decoding tasks</li> <li>Configuration Guide - Understanding and configuring experiments</li> <li>Task Reference - Complete reference for all available tasks</li> <li>Registry API Reference - Registry decorators and function signatures</li> </ol>"},{"location":"#overview","title":"Overview","text":"<p>This framework provides a flexible system for: - Training neural decoding models on iEEG data - Comparing different model architectures - Evaluating performance across multiple metrics - Running systematic hyperparameter searches</p> <p>For long updates and discussions, see this notebook.</p>"},{"location":"adding-task/","title":"Adding a New Task","text":"<p>Guide to implementing custom decoding tasks beyond word embedding prediction.</p>"},{"location":"adding-task/#overview","title":"Overview","text":"<p>A task defines what you're trying to decode from neural data. The default task is word embedding decoding, but you can create tasks for any prediction target aligned with temporal events in your data: - Phoneme prediction - Sentiment classification - Grammatical role prediction - Part-of-speech tagging - Syllable-level features - Any other prediction target with associated timing information</p>"},{"location":"adding-task/#quick-reference","title":"Quick Reference","text":"<p>To add a new task:</p> <ol> <li>Create a task data getter function</li> <li>Register the function</li> <li>Update your config</li> <li>Optional: Add custom metrics</li> </ol>"},{"location":"adding-task/#1-create-task-data-getter","title":"1. Create Task Data Getter","text":"<p>Create a new file in tasks/ with a function that loads and processes your task-specific data.</p>"},{"location":"adding-task/#function-signature","title":"Function Signature","text":"<pre><code>from core.config import DataParams\n\ndef my_task_data_getter(data_params: DataParams) -&gt; pd.DataFrame:\n    \"\"\"\n    Load task-specific data.\n\n    Args:\n        data_params: DataParams object with configuration\n\n    Returns:\n        DataFrame with required columns:\n        - start: Time to center neural data around (seconds)\n        - target: Target variable for prediction\n        - word: (Optional) The text/label for this event\n    \"\"\"\n    pass\n</code></pre> <p>Required DataFrame Columns: - <code>start</code> (float): Timestamp to center the neural data window around (in seconds) - <code>target</code> (any): The prediction target (can be embeddings, labels, scalars, etc.)</p> <p>Optional Columns: - <code>word</code> (str): Text/label for the event (useful for zero-shot folds) - Any other metadata you want to track</p>"},{"location":"adding-task/#minimal-example","title":"Minimal Example","text":"<pre><code>from core.config import DataParams\nimport pandas as pd\nimport core.registry as registry\n\n@registry.register_task_data_getter()\ndef constant_prediction_task(data_params: DataParams):\n    \"\"\"Simple task: predict a constant value.\"\"\"\n    # Load timing data\n    transcript_path = os.path.join(\n        data_params.data_root,\n        \"stimuli/gpt2-xl/transcript.tsv\"\n    )\n    df = pd.read_csv(transcript_path, sep=\"\\t\")\n\n    # Group tokens into words and get start times\n    df_word = df.groupby(\"word_idx\").agg(dict(start=\"first\"))\n\n    # Set target to constant (model learns to output 1.0)\n    df_word[\"target\"] = 1.0\n\n    return df_word\n</code></pre>"},{"location":"adding-task/#2-register-the-function","title":"2. Register the Function","text":"<p>Use the <code>@registry.register_task_data_getter()</code> decorator:</p> <pre><code>import core.registry as registry\n\n@registry.register_task_data_getter()\ndef my_custom_task(data_params: DataParams):\n    # Your implementation\n    return df_word\n</code></pre> <p>Optional: Specify a custom name: <pre><code>@registry.register_task_data_getter('custom_name')\ndef my_function(data_params: DataParams):\n    ...\n</code></pre></p>"},{"location":"adding-task/#3-update-config","title":"3. Update Config","text":"<p>Set the <code>task_name</code> in your config file:</p> <pre><code># Specify your task\ntask_name: my_custom_task\n\n# Pass task-specific parameters via task_params\ndata_params:\n  task_params:\n    custom_param: value\n    another_param: 123\n</code></pre> <p>Access task parameters in your function: <pre><code>def my_custom_task(data_params: DataParams):\n    custom_value = data_params.task_params['custom_param']\n    ...\n</code></pre></p>"},{"location":"adding-task/#4-optional-custom-metrics","title":"4. Optional: Custom Metrics","text":"<p>Define metrics specific to your task. Add them to the appropriate file in the <code>metrics/</code> package based on the metric type:</p> <ul> <li>Regression metrics \u2192 <code>metrics/regression_metrics.py</code></li> <li>Classification metrics \u2192 <code>metrics/classification_metrics.py</code></li> <li>Embedding metrics \u2192 <code>metrics/embedding_metrics.py</code></li> <li>Utility functions \u2192 <code>metrics/utils.py</code></li> </ul> <p>Example:</p> <pre><code>import torch\nfrom core.registry import register_metric\n\n@register_metric('my_accuracy')\ndef my_accuracy_metric(predicted: torch.Tensor, groundtruth: torch.Tensor):\n    \"\"\"\n    Custom metric for your task.\n\n    Args:\n        predicted: Model predictions [batch_size, ...]\n        groundtruth: Ground truth targets [batch_size, ...]\n\n    Returns:\n        Scalar metric value\n    \"\"\"\n    correct = (predicted.argmax(dim=1) == groundtruth).float()\n    return correct.mean()\n</code></pre> <p>Then add to your config: <pre><code>training_params:\n  losses: [cross_entropy]\n  metrics: [my_accuracy, cosine_sim]\n</code></pre></p> <p>The metrics are automatically registered when the package is imported.</p>"},{"location":"adding-task/#examples","title":"Examples","text":"<p>See the <code>tasks/</code> directory for complete examples: - <code>tasks/word_embedding.py</code> - Default task for decoding word embeddings - <code>tasks/placeholder_task.py</code> - Minimal example showing required structure - <code>tasks/content_noncontent.py</code> - Binary classification example - <code>tasks/pos_task.py</code> - Part-of-speech tagging example - <code>tasks/sentence_onset.py</code> - Sentence onset detection - <code>tasks/gpt_surprise.py</code> - Regression and multiclass classification examples - <code>tasks/volume_level.py</code> - Audio feature prediction with custom config setter</p> <p>For detailed documentation on all available tasks and their configuration parameters, see the Task Reference</p>"},{"location":"adding-task/#task-parameters","title":"Task Parameters","text":"<p>Pass task-specific configuration via <code>data_params.task_params</code>:</p> <pre><code>data_params:\n  task_params:\n    feature_file: \"path/to/features.csv\"\n    threshold: 0.5\n    use_lemmas: true\n</code></pre> <p>Access in your function: <pre><code>from core.config import DataParams\n\ndef my_task(data_params: DataParams):\n    feature_file = data_params.task_params['feature_file']\n    threshold = data_params.task_params.get('threshold', 0.5)\n    ...\n</code></pre></p>"},{"location":"adding-task/#see-also","title":"See Also","text":"<ul> <li>Task Reference - Complete reference for all available tasks</li> <li>Configuration Guide - How to configure tasks</li> <li>API Reference - Task data getter API</li> <li><code>tasks/</code> directory - Complete task examples</li> </ul>"},{"location":"api-reference/","title":"Registry API Reference","text":"<p>Reference for all registry decorators and their function signatures.</p>"},{"location":"api-reference/#overview","title":"Overview","text":"<p>The framework uses registries to discover and manage model components. Decorate your functions with the appropriate registry decorator to make them available to the training pipeline.</p> <p>Module: <code>core/registry.py</code></p>"},{"location":"api-reference/#register_model_constructornamenone","title":"<code>@register_model_constructor(name=None)</code>","text":"<p>Register a function that constructs your decoding model.</p>"},{"location":"api-reference/#purpose","title":"Purpose","text":"<p>Creates model instances from config parameters. Called during training setup.</p>"},{"location":"api-reference/#function-signature","title":"Function Signature","text":"<pre><code>def model_constructor(model_params: dict) -&gt; nn.Module\n</code></pre>"},{"location":"api-reference/#arguments","title":"Arguments","text":"<ul> <li><code>model_params</code> (dict): Parameters from your config's <code>model_params</code> section</li> </ul>"},{"location":"api-reference/#returns","title":"Returns","text":"<ul> <li>PyTorch model instance</li> </ul>"},{"location":"api-reference/#example","title":"Example","text":"<pre><code>@registry.register_model_constructor()\ndef my_model(model_params):\n    return MyModel(\n        input_dim=model_params['input_dim'],\n        output_dim=model_params['output_dim']\n    )\n</code></pre>"},{"location":"api-reference/#usage-in-config","title":"Usage in Config","text":"<pre><code>model_constructor_name: my_model\nmodel_params:\n  input_dim: 256\n  output_dim: 50\n</code></pre>"},{"location":"api-reference/#register_data_preprocessornamenone","title":"<code>@register_data_preprocessor(name=None)</code>","text":"<p>Register a function that preprocesses neural data.</p>"},{"location":"api-reference/#purpose_1","title":"Purpose","text":"<p>Transforms raw neural data into the format your model expects. Called once before training.</p>"},{"location":"api-reference/#function-signature_1","title":"Function Signature","text":"<pre><code>def preprocessor(\n    data: np.ndarray,  # [num_events, num_electrodes, timesteps]\n    preprocessor_params: dict\n) -&gt; np.ndarray  # [num_events, ...]\n</code></pre>"},{"location":"api-reference/#arguments_1","title":"Arguments","text":"<ul> <li><code>data</code> (np.ndarray): Raw neural data with shape <code>[num_events, num_electrodes, timesteps]</code></li> <li><code>preprocessor_params</code> (dict): Parameters from your config's <code>data_params.preprocessor_params</code></li> </ul>"},{"location":"api-reference/#returns_1","title":"Returns","text":"<ul> <li>Preprocessed data with shape <code>[num_events, ...]</code> (any shape your model needs)</li> </ul>"},{"location":"api-reference/#example_1","title":"Example","text":"<pre><code>@registry.register_data_preprocessor()\ndef my_preprocessor(data, preprocessor_params):\n    # Average over time\n    n_avg = preprocessor_params['num_average_samples']\n    return data.reshape(data.shape[0], data.shape[1], -1, n_avg).mean(-1)\n</code></pre>"},{"location":"api-reference/#usage-in-config_1","title":"Usage in Config","text":"<pre><code>data_params:\n  preprocessing_fn_name: my_preprocessor\n  preprocessor_params:\n    num_average_samples: 32\n</code></pre>"},{"location":"api-reference/#register_config_setternamenone","title":"<code>@register_config_setter(name=None)</code>","text":"<p>Register a function that modifies config at runtime based on loaded data.</p>"},{"location":"api-reference/#purpose_2","title":"Purpose","text":"<p>Sets config values that depend on the data (e.g., number of channels, model dimensions). Called after data is loaded, before model construction.</p>"},{"location":"api-reference/#function-signature_2","title":"Function Signature","text":"<pre><code>def config_setter(\n    experiment_config: ExperimentConfig,\n    raws: list[mne.io.Raw],\n    df_word: pd.DataFrame\n) -&gt; ExperimentConfig\n</code></pre>"},{"location":"api-reference/#arguments_2","title":"Arguments","text":"<ul> <li><code>experiment_config</code> (ExperimentConfig): Your experiment configuration</li> <li><code>raws</code> (list[mne.io.Raw]): Loaded neural recordings</li> <li><code>df_word</code> (pd.DataFrame): Task data with event timings and targets</li> </ul>"},{"location":"api-reference/#returns_2","title":"Returns","text":"<ul> <li>Modified <code>ExperimentConfig</code></li> </ul>"},{"location":"api-reference/#example_2","title":"Example","text":"<pre><code>@registry.register_config_setter()\ndef my_config_setter(experiment_config, raws, df_word):\n    # Set input channels based on loaded data\n    num_channels = sum([len(raw.ch_names) for raw in raws])\n    experiment_config.model_params['input_channels'] = num_channels\n    return experiment_config\n</code></pre>"},{"location":"api-reference/#usage-in-config_2","title":"Usage in Config","text":"<pre><code>config_setter_name: my_config_setter\n</code></pre>"},{"location":"api-reference/#register_metricnamenone","title":"<code>@register_metric(name=None)</code>","text":"<p>Register a metric or loss function.</p>"},{"location":"api-reference/#purpose_3","title":"Purpose","text":"<p>Defines objectives for training (losses) or evaluation (metrics). Called during each training step.</p>"},{"location":"api-reference/#function-signature_3","title":"Function Signature","text":"<pre><code>def metric(\n    predicted: torch.Tensor,\n    groundtruth: torch.Tensor\n) -&gt; float\n</code></pre>"},{"location":"api-reference/#arguments_3","title":"Arguments","text":"<ul> <li><code>predicted</code> (torch.Tensor): Model predictions <code>[batch_size, ...]</code></li> <li><code>groundtruth</code> (torch.Tensor): Ground truth targets <code>[batch_size, ...]</code></li> </ul>"},{"location":"api-reference/#returns_3","title":"Returns","text":"<ul> <li>Scalar metric value (float or torch scalar)</li> </ul>"},{"location":"api-reference/#example_3","title":"Example","text":"<pre><code>@registry.register_metric()\ndef my_loss(predicted, groundtruth):\n    return F.mse_loss(predicted, groundtruth)\n</code></pre>"},{"location":"api-reference/#usage-in-config_3","title":"Usage in Config","text":"<pre><code>training_params:\n  losses: [my_loss, mse]\n  loss_weights: [0.5, 0.5]\n  metrics: [cosine_sim]\n</code></pre>"},{"location":"api-reference/#register_task_data_getternamenone","title":"<code>@register_task_data_getter(name=None)</code>","text":"<p>Register a function that loads task-specific data.</p>"},{"location":"api-reference/#purpose_4","title":"Purpose","text":"<p>Loads event timings and targets for your decoding task. Called once at the start of training.</p>"},{"location":"api-reference/#function-signature_4","title":"Function Signature","text":"<pre><code>def task_data_getter(data_params: DataParams) -&gt; pd.DataFrame\n</code></pre>"},{"location":"api-reference/#arguments_4","title":"Arguments","text":"<ul> <li><code>data_params</code> (DataParams): Data configuration from your config file</li> </ul>"},{"location":"api-reference/#returns_4","title":"Returns","text":"<ul> <li>DataFrame with required columns:</li> <li><code>start</code> (float): Event onset time in seconds</li> <li><code>target</code> (any): Prediction target (embeddings, labels, etc.)</li> <li><code>word</code> (str, optional): Event label (for zero-shot folds)</li> </ul>"},{"location":"api-reference/#example_4","title":"Example","text":"<pre><code>@registry.register_task_data_getter()\ndef my_task(data_params):\n    # Load timing data\n    df = pd.read_csv(data_params.task_params['data_file'])\n\n    # Create required columns\n    df['start'] = df['onset_time']\n    df['target'] = df['label'].values\n\n    return df[['start', 'target']]\n</code></pre>"},{"location":"api-reference/#usage-in-config_4","title":"Usage in Config","text":"<pre><code>task_name: my_task\ndata_params:\n  task_params:\n    data_file: path/to/data.csv\n</code></pre>"},{"location":"api-reference/#built-in-registered-functions","title":"Built-in Registered Functions","text":""},{"location":"api-reference/#models","title":"Models","text":"<p>See <code>models/neural_conv_decoder/decoder_model.py</code> and <code>models/example_foundation_model/integration.py</code> for examples.</p>"},{"location":"api-reference/#preprocessors","title":"Preprocessors","text":"<ul> <li><code>window_average_neural_data</code> - Temporal averaging (models/neural_conv_decoder)</li> <li><code>foundation_model_preprocessing_fn</code> - Extract frozen foundation model features</li> <li><code>foundation_model_finetune_mlp</code> - Prepare data for foundation model finetuning</li> </ul>"},{"location":"api-reference/#metrics","title":"Metrics","text":"<p>The metrics package is organized by task type:</p> <p>Regression Metrics (<code>metrics/regression_metrics.py</code>): - <code>mse</code> - Mean squared error - <code>corr</code> - Pearson correlation coefficient - <code>r2</code> - R\u00b2 score (coefficient of determination)</p> <p>Embedding Metrics (<code>metrics/embedding_metrics.py</code>): - <code>cosine_sim</code> - Cosine similarity - <code>cosine_dist</code> - Cosine distance - <code>nll_embedding</code> - Contrastive NLL - <code>similarity_entropy</code> - Similarity distribution entropy</p> <p>Classification Metrics (<code>metrics/classification_metrics.py</code>): - <code>bce</code> - Binary cross-entropy (weighted) - <code>cross_entropy</code> - Multi-class cross-entropy - <code>roc_auc</code> - ROC-AUC for binary classification - <code>roc_auc_multiclass</code> - ROC-AUC for multi-class classification - <code>f1</code> - F1 score - <code>sensitivity</code> - Sensitivity (recall/TPR) - <code>precision</code> - Precision - <code>specificity</code> - Specificity (TNR) - <code>confusion_matrix</code> - Confusion matrix - <code>perplexity</code> - Perplexity (for LLM evaluation)</p> <p>Utility Functions (<code>metrics/utils.py</code>): - <code>compute_cosine_distances</code> - Cosine distance computation with ensemble support - <code>compute_class_scores</code> - Convert distances to class probabilities - <code>calculate_auc_roc</code> - AUC-ROC with frequency filtering - <code>top_k_accuracy</code> - Top-k accuracy calculation - <code>entropy</code> - Entropy computation for distributions</p> <p>See the <code>metrics/</code> package for complete implementations.</p>"},{"location":"api-reference/#tasks","title":"Tasks","text":"<ul> <li><code>word_embedding_decoding_task</code> - Decode word embeddings (default)</li> <li><code>placeholder_task</code> - Minimal example</li> <li><code>content_noncontent_task</code> - Content vs non-content classification</li> <li><code>gpt_surprise_task</code> - GPT surprisal prediction</li> <li><code>gpt_surprise_multiclass_task</code> - GPT surprisal multiclass classification</li> <li><code>pos_task</code> - Part-of-speech tagging</li> <li><code>sentence_onset_task</code> - Sentence onset detection</li> <li><code>volume_level_encoding_task</code> - Audio volume level prediction</li> </ul> <p>See <code>tasks/</code> directory for implementations.</p>"},{"location":"api-reference/#see-also","title":"See Also","text":"<ul> <li>Onboarding a Model - How to use registries</li> <li>Adding a Task - Task data getter details</li> <li>Configuration Guide - Config structure</li> </ul>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>Complete guide to configuring experiments in the podcast benchmark framework.</p>"},{"location":"configuration/#overview","title":"Overview","text":"<p>All experiments are configured via YAML files in the <code>configs/</code> directory. Each config file has four main sections that control different aspects of your experiment.</p>"},{"location":"configuration/#configuration-structure","title":"Configuration Structure","text":"<pre><code># Which model and task to use\nmodel_constructor_name: my_model\nconfig_setter_name: my_config_setter  # Optional\ntask_name: word_embedding_decoding_task  # Optional\n\n# Model-specific parameters\nmodel_params:\n  # Fully customizable - passed to your model constructor\n\n# How to train\ntraining_params:\n  # Batch size, learning rate, losses, metrics, etc.\n\n# What data to use\ndata_params:\n  # Subjects, electrodes, embeddings, preprocessing\n\n# Where to save results\noutput_dir: results\nmodel_dir: models\ntrial_name: my_experiment\n</code></pre>"},{"location":"configuration/#model-parameters","title":"Model Parameters","text":"<p>Purpose: Define architecture and hyperparameters for your specific model.</p> <p>This section is completely customizable - whatever you put here gets passed directly to your model constructor function. The framework doesn't impose any specific fields.</p> <p>Example: <pre><code>model_params:\n  hidden_dim: 512\n  num_layers: 3\n  dropout: 0.2\n  # Anything your model needs\n</code></pre></p>"},{"location":"configuration/#training-parameters","title":"Training Parameters","text":"<p>Purpose: Control the training loop, optimization, and evaluation.</p> <p>Key concepts: - Losses and metrics: What to optimize and track - Cross-validation: How to split data into folds - Early stopping: When to stop training - Time lags: Temporal relationship between neural data and events</p> <p>Particularly useful fields:</p> <pre><code>training_params:\n  # Loss configuration\n  losses: [mse, cosine_dist]    # Can combine multiple losses\n  loss_weights: [0.7, 0.3]      # Weight for each loss\n  metrics: [cosine_sim]         # Additional metrics to track (not in loss)\n\n  # Early stopping\n  early_stopping_metric: cosine_sim  # What metric to monitor\n  smaller_is_better: false          # false for accuracy/similarity, true for error\n\n  # Cross-validation strategy\n  fold_type: sequential_folds   # or \"zero_shot_folds\" for words not in training\n  n_folds: 5\n\n  # Time lags - find optimal temporal offset\n  min_lag: -500      # Start 500ms before word onset\n  max_lag: 1000      # End 1000ms after word onset\n  lag_step_size: 100 # Test every 100ms\n\n  # Baseline models\n  linear_regression_baseline: false    # Train and evaluate linear regression baseline\n  logistic_regression_baseline: false  # Train and evaluate logistic regression baseline\n</code></pre> <p>See <code>core/config.py:TrainingParams</code> for all available fields.</p>"},{"location":"configuration/#data-parameters","title":"Data Parameters","text":"<p>Purpose: Specify which subjects, electrodes, and data to use.</p> <p>Key concepts: - Subject selection: Which participants to include - Electrode selection: Which brain regions to decode from - Embeddings: What target representations to predict - Preprocessing: How to transform raw neural data</p> <p>Particularly useful fields:</p>"},{"location":"configuration/#electrode-selection","title":"Electrode Selection","text":"<p>You have three options for choosing which electrodes to use:</p> <pre><code>data_params:\n  # Option 1: Regular expression (most flexible)\n  channel_reg_ex: \"LG[AB]*\"  # Channels starting with LGA or LGB\n  # Examples:\n  #   \"^G([1-9]|[1-5][0-9]|6[0-4])$\"  - Channels G1-G64\n  #   \".*\"  - All channels\n\n  # Option 2: CSV file with electrode list\n  electrode_file_path: configs/significant_electrodes.csv\n  # Format: subject,elec\n\n  # Option 3: Per-subject dictionary\n  per_subject_electrodes:\n    1: [LGA1, LGA2, LGA3]\n    2: [LGB1, LGB2]\n</code></pre>"},{"location":"configuration/#other-key-fields","title":"Other Key Fields","text":"<pre><code>data_params:\n  subject_ids: [1, 2, 3]        # Which subjects to include\n\n  # Target embeddings\n  embedding_type: gpt-2xl       # \"gpt-2xl\", \"glove\", or \"arbitrary\"\n  embedding_layer: 24           # Which layer to extract (for GPT-2)\n  embedding_pca_dim: 50         # Optional dimensionality reduction\n\n  # Neural data window\n  window_width: 0.625           # Width of data window in seconds\n\n  # Preprocessing\n  preprocessing_fn_name: my_preprocessor  # Your registered function\n  preprocessor_params:          # Custom params for your preprocessor\n    param1: value1\n\n  # Task configuration\n  task_name: my_custom_task     # Optional, defaults to word embeddings\n  word_column: lemmatized_word  # For zero-shot folds\n  task_params:                  # Task-specific parameters\n    param1: value1\n</code></pre> <p>See <code>core/config.py:DataParams</code> for all available fields.</p>"},{"location":"configuration/#output-configuration","title":"Output Configuration","text":"<p>Purpose: Name your experiment and specify where results are saved.</p> <pre><code># Dynamic trial naming with formatting\ntrial_name: \"model_{}_lr={}_bs={}\"\nformat_fields:\n  - model_params.model_name\n  - training_params.learning_rate\n  - training_params.batch_size\n\n# Output directories\noutput_dir: results           # CSV files with metrics\nmodel_dir: models            # Saved model checkpoints\ntensorboard_dir: event_logs  # TensorBoard logs\n</code></pre>"},{"location":"configuration/#common-patterns","title":"Common Patterns","text":""},{"location":"configuration/#pattern-1-selecting-significant-electrodes-only","title":"Pattern 1: Selecting Significant Electrodes Only","text":"<pre><code>data_params:\n  electrode_file_path: configs/significant_electrodes.csv\n</code></pre>"},{"location":"configuration/#pattern-2-multi-loss-training","title":"Pattern 2: Multi-Loss Training","text":"<pre><code>training_params:\n  losses: [mse, cosine_dist]\n  loss_weights: [0.7, 0.3]\n  early_stopping_metric: cosine_sim  # Can use a metric not in losses\n</code></pre>"},{"location":"configuration/#pattern-3-finding-optimal-time-lag","title":"Pattern 3: Finding Optimal Time Lag","text":"<pre><code>training_params:\n  min_lag: -1000    # 1 second before word\n  max_lag: 2000     # 2 seconds after word\n  lag_step_size: 100\n\n# Results saved to {output_dir}/lag_performance.csv\n</code></pre>"},{"location":"configuration/#pattern-4-zero-shot-evaluation","title":"Pattern 4: Zero-Shot Evaluation","text":"<p>Test on words never seen during training:</p> <pre><code>training_params:\n  fold_type: zero_shot_folds\n\ndata_params:\n  word_column: lemmatized_word\n</code></pre>"},{"location":"configuration/#pattern-5-quick-debugging-run","title":"Pattern 5: Quick Debugging Run","text":"<pre><code>data_params:\n  subject_ids: [1]  # Single subject\n\ntraining_params:\n  epochs: 10\n  n_folds: 2\n  lag: 0  # Single lag instead of sweep\n</code></pre>"},{"location":"configuration/#batch-training-with-training-matrix","title":"Batch Training with Training Matrix","text":"<p>The <code>training_matrix.yaml</code> file enables running multiple experiments at once. Define model/task/config combinations:</p> <pre><code>neural_conv_decoder:\n  word_embedding_decoding_task:\n    - neural_conv_decoder_base.yml\n    - neural_conv_decoder_binary.yml\n</code></pre> <p>Usage: <pre><code>make train-all                                    # Run all configs\nmake train-all MODELS=neural_conv_decoder         # Filter by model\nmake train-all TASKS=sentence_onset_task          # Filter by task\nmake train-all MODELS=model1,model2 TASKS=task1   # Combine filters\n</code></pre></p> <p>Adding New Model/Task Combinations:</p> <p>Edit <code>training_matrix.yaml</code> to add your experiments:</p> <pre><code>your_new_model:\n  your_new_task:\n    - config_file_1.yml\n    - config_file_2.yml\n    - config_file_3.yml\n</code></pre>"},{"location":"configuration/#see-also","title":"See Also","text":"<ul> <li><code>core/config.py</code>: Source code with all available fields and defaults</li> <li><code>training_matrix.yaml</code>: Batch experiment configuration</li> <li>Task Reference: Complete reference for all available tasks</li> <li>Onboarding a Model: How to use configs with your models</li> <li>API Reference: Detailed API documentation</li> </ul>"},{"location":"onboarding-model/","title":"Onboarding a New Model","text":"<p>Complete guide to adding your own decoding model to the framework.</p>"},{"location":"onboarding-model/#quick-reference","title":"Quick Reference","text":"<p>To set up a new model (e.g., BrainBERT), you need to:</p> <ol> <li>Create a new folder for your model code</li> <li>Define a decoding model and constructor function</li> <li>Define a data preprocessing function</li> <li>Create a config file</li> <li>Optional: Define a config setter function</li> <li>Import your module in main.py</li> <li>Optional: Update the Makefile</li> <li>Run your training code</li> </ol>"},{"location":"onboarding-model/#1-create-a-new-folder","title":"1. Create a New Folder","text":"<p>Organize all code for your model in its own directory inside the <code>models/</code> folder:</p> <pre><code>mkdir models/my_model\n</code></pre> <p>Write all model-specific code in this folder.</p>"},{"location":"onboarding-model/#2-define-decoding-model-and-constructor","title":"2. Define Decoding Model and Constructor","text":""},{"location":"onboarding-model/#define-your-model","title":"Define Your Model","text":"<p>Create your PyTorch model in <code>models/my_model/model.py</code>. For example:</p> <pre><code>import torch.nn as nn\n\nclass MyDecodingModel(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 512)\n        self.fc2 = nn.Linear(512, output_dim)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        return self.fc2(x)\n</code></pre>"},{"location":"onboarding-model/#create-a-constructor-function","title":"Create a Constructor Function","text":"<p>Define a constructor that takes model parameters from your config:</p> <pre><code>import core.registry as registry\n\n@registry.register_model_constructor()\ndef my_model_constructor(model_params):\n    return MyDecodingModel(\n        input_dim=model_params['input_dim'],\n        output_dim=model_params['output_dim']\n    )\n</code></pre> <p>Important: - Use the <code>@registry.register_model_constructor()</code> decorator - The function must have signature: <code>constructor_fn(model_params: dict) -&gt; Model</code> - By default, the registered name is the function name (can override with <code>@registry.register_model_constructor('custom_name')</code>)</p>"},{"location":"onboarding-model/#examples","title":"Examples","text":"<p>Neural Conv Decoder (ensemble model): <pre><code>@registry.register_model_constructor()\ndef ensemble_pitom_model(model_params):\n    return EnsemblePitomModel(\n        num_models=model_params['num_models'],\n        input_channels=model_params['input_channels'],\n        output_dim=model_params['embedding_dim'],\n        conv_filters=model_params['conv_filters'],\n        reg=model_params['reg'],\n        reg_head=model_params['reg_head'],\n        dropout=model_params['dropout']\n    )\n</code></pre></p> <p>Foundation Model with Finetuning:</p> <p>When finetuning a foundation model, you include it as part of your decoder class:</p> <pre><code>class FoundationModelMLP(nn.Module):\n    def __init__(\n        self,\n        input_dim,\n        mlp_layer_sizes,\n        model_dir=None,\n        finetune=False,\n        foundation_model_config=None,\n        freeze_foundation_model=False,\n        num_unfrozen_blocks=0,\n    ):\n        super().__init__()\n        self.finetune = finetune\n\n        # Include foundation model as part of decoder if finetuning\n        if finetune:\n            self.foundation_model = create_and_freeze_foundation_model(\n                foundation_model_config,\n                model_dir,\n                freeze_foundation_model,\n                num_unfrozen_blocks,\n            )\n\n        self.embedding_norm = nn.BatchNorm1d(input_dim)\n        self.mlp = MLP(input_dim, mlp_layer_sizes)\n\n    def forward(self, x):\n        # Pass through foundation model if finetuning\n        if self.finetune:\n            x = self.foundation_model(x, forward_features=True)\n\n        x = self.embedding_norm(x)\n        return self.mlp(x)\n\n\n@registry.register_model_constructor()\ndef foundation_model_finetune_mlp(model_params):\n    return FoundationModelMLP(\n        model_params[\"model_dim\"],\n        model_params[\"mlp_layer_sizes\"],\n        model_dir=model_params.get(\"model_dir\"),\n        foundation_model_config=model_params[\"foundation_model_config\"],\n        finetune=True,\n        freeze_foundation_model=model_params.get(\"freeze_foundation_model\", False),\n        num_unfrozen_blocks=model_params.get(\"num_unfrozen_blocks\", 0),\n    )\n</code></pre> <p>Key Points for Finetuning: - Your decoder model includes the foundation model as a submodule - The foundation model is loaded with pretrained weights in <code>__init__</code> - You can optionally freeze parts of the foundation model - The <code>forward()</code> method runs data through both the foundation model and your decoder head</p>"},{"location":"onboarding-model/#3-define-data-preprocessing-function","title":"3. Define Data Preprocessing Function","text":"<p>Create a function to transform neural data for your model.</p> <pre><code>import core.registry as registry\n\n@registry.register_data_preprocessor()\ndef my_preprocessing_fn(data, preprocessor_params):\n    # data shape: [num_words, num_electrodes, timesteps]\n    # Return shape: [num_words, ...] (any shape your model expects)\n\n    # Example: average over time\n    return data.mean(axis=-1)\n</code></pre> <p>Function Signature: <pre><code>import numpy as np\n\ndef preprocessing_fn(\n    data: np.array,  # [num_words, num_electrodes, timesteps]\n    preprocessor_params: dict\n) -&gt; np.array  # [num_words, ...]\n</code></pre></p>"},{"location":"onboarding-model/#examples_1","title":"Examples","text":"<p>Neural Conv Decoder (temporal averaging): <pre><code>@registry.register_data_preprocessor()\ndef window_average_neural_data(data, preprocessor_params):\n    # Average over num_average_samples to reduce sample rate\n    return data.reshape(\n        data.shape[0],\n        data.shape[1],\n        -1,\n        preprocessor_params['num_average_samples']\n    ).mean(-1)\n</code></pre></p> <p>Foundation Model with Finetuning (prepare for model input):</p> <p>When finetuning, your preprocessing function prepares the data in the format your foundation model expects:</p> <pre><code>@registry.register_data_preprocessor(\"foundation_model_finetune_mlp\")\ndef prepare_data_for_finetuning(data, preprocessor_params):\n    \"\"\"Prepare neural data for foundation model input.\"\"\"\n    data_config = preprocessor_params[\"ecog_data_config\"]\n\n    # Downsample temporal resolution\n    data = data.reshape(\n        data.shape[0],\n        data.shape[1],\n        -1,\n        data_config.original_fs // data_config.new_fs\n    )\n    data = data.mean(-1)\n\n    # Pad to expected electrode grid (e.g., 64 channels)\n    for i in range(64):\n        channel = \"G\" + str(i + 1)\n        if channel not in preprocessor_params['ch_names']:\n            # Insert NaN for missing channels\n            data = np.insert(data, i, np.nan, axis=1)\n\n    # Reshape to spatial grid: [num_examples, bands, time, height, width]\n    data = np.einsum('bet-&gt;bte', data).reshape(data.shape[0], data.shape[2], 8, 8)\n    data = np.expand_dims(data, axis=1)\n\n    return data\n</code></pre> <p>Key Points: - When not finetuning: Extract frozen representations in preprocessing, return embeddings - When finetuning: Format raw data for model input, let the model extract features during training</p>"},{"location":"onboarding-model/#4-create-config-file","title":"4. Create Config File","text":"<p>Create a YAML config file in <code>configs/my_model/config.yml</code>.</p> <p>See Configuration Guide for detailed documentation on all config options.</p>"},{"location":"onboarding-model/#basic-example","title":"Basic Example","text":"<pre><code># Model constructor name (must match registered function name)\nmodel_constructor_name: my_model_constructor\n\n# Optional: config setter function name\nconfig_setter_name: my_config_setter\n\n# Model-specific parameters (passed to constructor)\nmodel_params:\n  input_dim: 256\n  output_dim: 50\n\n# Training parameters\ntraining_params:\n  batch_size: 32\n  epochs: 100\n  learning_rate: 0.001\n  weight_decay: 0.0001\n  early_stopping_patience: 10\n  n_folds: 5\n  losses: [mse]\n  metrics: [cosine_sim]\n  early_stopping_metric: cosine_sim\n\n# Data parameters\ndata_params:\n  data_root: data\n  embedding_type: gpt-2xl\n  embedding_layer: 24\n  window_width: 0.625\n  preprocessing_fn_name: my_preprocessing_fn\n  subject_ids: [1, 2, 3]\n  preprocessor_params:\n    custom_param: value\n\n# Trial identifier\ntrial_name: my_model_v1\n</code></pre>"},{"location":"onboarding-model/#finetuning-example","title":"Finetuning Example","text":"<pre><code>model_constructor_name: foundation_model_finetune_mlp\nconfig_setter_name: foundation_model_finetune_mlp\n\nmodel_params:\n  mlp_layer_sizes: [50]\n  norm_embedding: true\n  # Path to pretrained foundation model\n  model_dir: /path/to/pretrained/model\n  # Optionally freeze most of foundation model\n  freeze_foundation_model: true\n  num_unfrozen_blocks: 2  # Only finetune last 2 transformer blocks\n\ntraining_params:\n  batch_size: 64\n  learning_rate: 0.001\n  losses: [mse]\n  metrics: [cosine_sim, nll_embedding]\n  early_stopping_metric: cosine_sim\n\ndata_params:\n  data_root: data\n  embedding_type: gpt-2xl\n  embedding_layer: 24\n  embedding_pca_dim: 50\n  preprocessing_fn_name: foundation_model_finetune_mlp\n  subject_ids: [1, 2, 3]\n\ntrial_name: foundation_finetune_v1\n</code></pre>"},{"location":"onboarding-model/#5-optional-define-config-setter","title":"5. Optional: Define Config Setter","text":"<p>Sometimes you need to set config values at runtime based on the loaded data.</p> <pre><code>import core.registry as registry\n\n@registry.register_config_setter('my_model')\ndef my_config_setter(experiment_config, raws, df_word):\n    # Set values based on data\n    num_electrodes = sum([len(raw.ch_names) for raw in raws])\n    experiment_config.model_params['input_channels'] = num_electrodes\n    return experiment_config\n</code></pre> <p>Function Signature: <pre><code>from core.config import ExperimentConfig\n\ndef config_setter(\n    experiment_config: ExperimentConfig,\n    raws: list[mne.io.Raw],\n    df_word: pd.DataFrame\n) -&gt; ExperimentConfig\n</code></pre></p>"},{"location":"onboarding-model/#examples_2","title":"Examples","text":"<p>Neural Conv (set number of input channels): <pre><code>@registry.register_config_setter('neural_conv')\ndef set_config_input_channels(experiment_config, raws, _df_word):\n    num_electrodes = sum([len(raw.ch_names) for raw in raws])\n    experiment_config.model_params['input_channels'] = num_electrodes\n    return experiment_config\n</code></pre></p> <p>Foundation Model Finetuning (load foundation config and set dimensions): <pre><code>@registry.register_config_setter(\"foundation_model_finetune_mlp\")\ndef foundation_model_mlp_finetune_config_setter(\n    experiment_config, raws, _df_word\n):\n    # Add channel names for preprocessing\n    ch_names = sum([raw.info.ch_names for raw in raws], [])\n    experiment_config.data_params.preprocessor_params = {\"ch_names\": ch_names}\n\n    # Load foundation model config\n    config_path = os.path.join(\n        experiment_config.model_params[\"model_dir\"],\n        \"experiment_config.yml\"\n    )\n    foundation_config = load_config(config_path)\n\n    # Set dimensions and window width from foundation model\n    experiment_config.model_params[\"foundation_model_config\"] = foundation_config\n    experiment_config.model_params[\"model_dim\"] = foundation_config.vit_config.dim\n    experiment_config.data_params.window_width = foundation_config.sample_length\n    experiment_config.data_params.preprocessor_params[\"ecog_data_config\"] = (\n        foundation_config.ecog_data_config\n    )\n\n    return experiment_config\n</code></pre></p>"},{"location":"onboarding-model/#6-import-module","title":"6. Import Module","text":"<p>Your module will be automatically imported! The framework recursively imports all models from the <code>models/</code> directory:</p> <pre><code># Import all models from the models/ directory (recursively imports all subpackages)\nimport_all_from_package(\"models\", recursive=True)\n</code></pre> <p>As long as your model is in <code>models/my_model/</code>, it will be automatically discovered and loaded at runtime.</p> <p>Critical: Make sure you've added the <code>@registry</code> decorators to your functions!</p>"},{"location":"onboarding-model/#7-optional-update-makefile","title":"7. Optional: Update Makefile","text":"<p>Add a convenient make rule for your model:</p> <pre><code>my-model:\n    mkdir -p logs\n    $(CMD) main.py \\\n        --config configs/my_model/config.yml\n</code></pre> <p>Now you can run with: <pre><code>make my-model\n</code></pre></p>"},{"location":"onboarding-model/#8-run-training","title":"8. Run Training","text":"<p>Run your model:</p> <pre><code>make my-model\n</code></pre> <p>Or directly: <pre><code>python main.py --config configs/my_model/config.yml\n</code></pre></p> <p>Results will be saved to: - <code>results/</code> - Performance metrics - <code>models/</code> - Model checkpoints - <code>event_logs/</code> - TensorBoard logs (if enabled)</p>"},{"location":"onboarding-model/#debugging","title":"Debugging","text":"<p>If you encounter errors:</p> <ol> <li>Check that all <code>@registry</code> decorators are present</li> <li>Verify your module is imported in <code>main.py</code></li> <li>Ensure function names match between config and registered functions</li> <li>Look at logs in <code>logs/</code> for SLURM jobs</li> </ol>"},{"location":"onboarding-model/#complete-working-example","title":"Complete Working Example","text":"<p>See <code>models/example_foundation_model/</code> for a complete, self-contained example demonstrating:</p> <ul> <li>Simple transformer foundation model implementation</li> <li>Both integration patterns (feature extraction + finetuning)</li> <li>Model directory structure with config and checkpoint</li> <li>Full documentation and runnable examples</li> </ul> <p>This example shows exactly how all the pieces fit together for foundation models.</p> <pre><code># Run feature extraction example\npython main.py --config configs/example_foundation_model/feature_extraction.yaml\n\n# Run finetuning example\npython main.py --config configs/example_foundation_model/finetuning.yaml\n</code></pre> <p>See <code>models/example_foundation_model/README.md</code> for details.</p>"},{"location":"onboarding-model/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide - Detailed config options and patterns</li> <li>Task Reference - Complete reference for all available tasks</li> <li>Adding a Task - Create custom decoding tasks</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Get started with the podcast benchmark framework in minutes.</p>"},{"location":"quickstart/#setup","title":"Setup","text":"<p>To download data and set up your local virtual environment:</p> <pre><code>./setup.sh\n</code></pre> <p>This will: - Create a Python virtual environment - Install all required dependencies - Download the necessary podcast listening data</p>"},{"location":"quickstart/#training-your-first-model","title":"Training Your First Model","text":"<p>The framework comes with two pre-configured models you can train immediately.</p>"},{"location":"quickstart/#1-neural-convolutional-decoder","title":"1. Neural Convolutional Decoder","text":"<p>This recreates the decoder from Tang et al. 2022, which decodes word embeddings directly from neural data:</p> <pre><code>make neural-conv\n</code></pre>"},{"location":"quickstart/#2-foundation-model-decoder","title":"2. Foundation Model Decoder","text":"<p>This trains a decoder from a foundation model's latent representations to word embeddings:</p> <pre><code>make foundation-model\n</code></pre>"},{"location":"quickstart/#results","title":"Results","text":"<p>Training results will be saved to: - <code>results/</code> - Performance metrics and CSV files - <code>models/</code> - Saved model checkpoints - <code>event_logs/</code> - TensorBoard logs</p>"},{"location":"quickstart/#configuration","title":"Configuration","text":"<p>To modify data, behavior, or hyperparameters:</p> <p>Edit the relevant configuration file in <code>configs/</code>: - <code>configs/neural_conv_decoder/</code> - Neural convolutional decoder settings - <code>configs/example_foundation_model/</code> - Foundation model decoder settings</p> <p>Model implementations can be found in the <code>models/</code> directory.</p> <p>See Onboarding a New Model for details on configuration options.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Add your own model</li> <li>Create a custom task</li> <li>View all available tasks</li> <li>Explore the API</li> </ul>"},{"location":"task-reference/","title":"Task Reference","text":"<p>Complete reference for all available tasks in the podcast benchmark framework.</p>"},{"location":"task-reference/#overview","title":"Overview","text":"<p>Tasks define what you want to decode from neural data. Each task provides a DataFrame with timestamps (<code>start</code>) and targets (<code>target</code>) that serve as training labels for your models.</p> <p>All tasks are located in the <code>tasks/</code> directory and must be registered using the <code>@registry.register_task_data_getter()</code> decorator.</p>"},{"location":"task-reference/#task-list","title":"Task List","text":"<ul> <li>word_embedding_decoding_task</li> <li>volume_level_decoding_task</li> <li>content_noncontent_task</li> <li>pos_task</li> <li>sentence_onset_task</li> <li>gpt_surprise_task</li> <li>gpt_surprise_multiclass_task</li> <li>placeholder_task</li> </ul>"},{"location":"task-reference/#word_embedding_decoding_task","title":"word_embedding_decoding_task","text":"<p>File: <code>tasks/word_embedding.py</code></p> <p>Description: Decode high-dimensional word embeddings from neural data. Supports GPT-2 XL contextual embeddings, GloVe static embeddings, or custom embeddings.</p> <p>Task Type: Regression (high-dimensional continuous targets)</p> <p>Output: - <code>start</code>: Word start time in seconds - <code>target</code>: Word embedding vector (list or array)</p>"},{"location":"task-reference/#configuration-parameters","title":"Configuration Parameters","text":"<p>Parameters are specified in <code>data_params</code> (not <code>task_params</code>):</p> Parameter Type Default Description <code>embedding_type</code> string Required Embedding type: <code>\"gpt-2xl\"</code>, <code>\"glove\"</code>, or <code>\"arbitrary\"</code> <code>embedding_layer</code> int 24 GPT-2 layer to extract (0-47 for GPT-2 XL) <code>embedding_pca_dim</code> int None Optional: reduce dimensionality with PCA"},{"location":"task-reference/#embedding-types","title":"Embedding Types","text":"<p><code>gpt-2xl</code>: Contextual embeddings from GPT-2 XL - Requires transcript at <code>{data_root}/stimuli/gpt2-xl/transcript.tsv</code> - Extracts embeddings from specified layer - Handles sub-word tokenization automatically</p> <p><code>glove</code>: Static word embeddings (GloVe) - Requires implementation in <code>tasks/word_embedding.py</code> - Uses lemmatized word forms - Fixed vectors per word type</p> <p><code>arbitrary</code>: Custom embedding implementation - Requires implementation in <code>utils/word_embedding.py</code> - Flexible for any embedding type</p>"},{"location":"task-reference/#word-processing","title":"Word Processing","text":"<p>The task automatically: 1. Groups sub-word tokens into full words using <code>word_idx</code> 2. Normalizes words (lowercase, remove punctuation) 3. Lemmatizes words using NLTK WordNet 4. Aligns embeddings to word boundaries</p>"},{"location":"task-reference/#example-config","title":"Example Config","text":"<pre><code>data_params:\n  task_name: word_embedding_decoding_task\n  embedding_type: gpt-2xl\n  embedding_layer: 24\n  embedding_pca_dim: 50  # Optional: reduce from 1600 to 50 dims\n</code></pre>"},{"location":"task-reference/#volume_level_decoding_task","title":"volume_level_decoding_task","text":"<p>File: <code>tasks/volume_level.py</code></p> <p>Description: Continuous audio intensity decoding task. Extracts perceptual loudness (in dB) from the podcast audio using Hilbert envelope extraction, low-pass filtering, and optional sliding-window aggregation.</p> <p>Task Type: Regression (continuous targets)</p> <p>Output: - <code>start</code>: Timestamp in seconds - <code>target</code>: Log-amplitude (dB) representing perceptual loudness</p>"},{"location":"task-reference/#configuration-parameters_1","title":"Configuration Parameters","text":"<p>All parameters are specified in <code>data_params.task_params</code>:</p> Parameter Type Default Description <code>audio_path</code> string <code>\"stimuli/podcast.wav\"</code> Path to audio file (relative to <code>data_root</code> or absolute) <code>target_sr</code> int <code>512</code> Target sampling rate for envelope (Hz) <code>audio_sr</code> int <code>44100</code> Expected audio sampling rate (Hz) <code>cutoff_hz</code> float <code>8.0</code> Low-pass filter cutoff frequency (Hz) <code>butter_order</code> int <code>4</code> Butterworth filter order <code>zero_phase</code> bool <code>true</code> Use zero-phase filtering (filtfilt) vs causal (filt) <code>log_eps</code> float auto Epsilon for log compression (auto: peak * 1e-6) <code>allow_resample_audio</code> bool <code>false</code> Allow audio with different sample rate than expected <code>window_size</code> float None Optional: sliding window width in milliseconds <code>hop_size</code> float <code>window_size</code> Optional: sliding window hop size in milliseconds"},{"location":"task-reference/#windowing-behavior","title":"Windowing Behavior","text":"<p>Without windowing (<code>window_size=None</code>): - Returns per-sample dB values - Timestamps are evenly spaced at <code>1/target_sr</code> intervals - Formula: <code>20 * log10(envelope + log_eps)</code></p> <p>With windowing: - Applies sliding RMS windows to the envelope - Converts each RMS window to dB - Timestamps are at window centers - More robust to noise, better aligned with neural integration windows</p>"},{"location":"task-reference/#example-config_1","title":"Example Config","text":"<pre><code>data_params:\n  task_name: volume_level_decoding_task\n  task_params:\n    audio_path: \"stimuli/podcast.wav\"\n    target_sr: 512\n    cutoff_hz: 8.0\n    window_size: 625    # 625ms windows\n    hop_size: 100       # 100ms hops\n    zero_phase: true\n</code></pre>"},{"location":"task-reference/#content_noncontent_task","title":"content_noncontent_task","text":"<p>File: <code>tasks/content_noncontent.py</code></p> <p>Description: Binary classification of content words (nouns, verbs, adjectives, adverbs) vs non-content words (determiners, prepositions, etc.).</p> <p>Task Type: Binary classification</p> <p>Output: - <code>start</code>: Word onset time in seconds - <code>target</code>: <code>1.0</code> for content words, <code>0.0</code> for non-content words</p>"},{"location":"task-reference/#configuration-parameters_2","title":"Configuration Parameters","text":"Parameter Type Default Description <code>content_noncontent_path</code> string <code>\"processed_data/df_word_onset_with_pos_class.csv\"</code> Path to CSV with word annotations (relative to cwd or absolute)"},{"location":"task-reference/#csv-format","title":"CSV Format","text":"<p>Expected columns: - <code>onset</code>: Word onset time in seconds - <code>is_content</code>: Binary label (1=content, 0=non-content)</p>"},{"location":"task-reference/#example-config_2","title":"Example Config","text":"<pre><code>data_params:\n  task_name: content_noncontent_task\n  task_params:\n    content_noncontent_path: \"processed_data/df_word_onset_with_pos_class.csv\"\n</code></pre>"},{"location":"task-reference/#pos_task","title":"pos_task","text":"<p>File: <code>tasks/pos_task.py</code></p> <p>Description: Multi-class part-of-speech classification for words.</p> <p>Task Type: Multi-class classification (5 classes)</p> <p>Classes: - <code>0</code>: Noun - <code>1</code>: Verb - <code>2</code>: Adjective - <code>3</code>: Adverb - <code>4</code>: Other</p> <p>Output: - <code>start</code>: Word onset time in seconds - <code>target</code>: Class label (0-4)</p>"},{"location":"task-reference/#configuration-parameters_3","title":"Configuration Parameters","text":"Parameter Type Default Description <code>pos_path</code> string <code>\"processed_data/df_word_onset_with_pos_class.csv\"</code> Path to CSV with POS annotations (relative to cwd or absolute)"},{"location":"task-reference/#csv-format_1","title":"CSV Format","text":"<p>Expected columns: - <code>onset</code>: Word onset time in seconds - <code>pos_class</code>: Integer class label (0-4)</p>"},{"location":"task-reference/#example-config_3","title":"Example Config","text":"<pre><code>data_params:\n  task_name: pos_task\n  task_params:\n    pos_path: \"processed_data/df_word_onset_with_pos_class.csv\"\n</code></pre>"},{"location":"task-reference/#sentence_onset_task","title":"sentence_onset_task","text":"<p>File: <code>tasks/sentence_onset.py</code></p> <p>Description: Binary classification for detecting sentence onsets. Includes positive examples at sentence starts and negative examples sampled away from onsets.</p> <p>Task Type: Binary classification</p> <p>Output: - <code>start</code>: Time in seconds - <code>target</code>: <code>1.0</code> for sentence onset, <code>0.0</code> for negative examples</p>"},{"location":"task-reference/#configuration-parameters_4","title":"Configuration Parameters","text":"Parameter Type Default Description <code>sentence_csv_path</code> string <code>\"processed_data/all_sentences_podcast.csv\"</code> Path to CSV with sentence boundaries (relative to cwd or absolute) <code>negatives_per_positive</code> int <code>1</code> Number of negative examples to sample per positive <code>negative_margin_s</code> float <code>2.0</code> Minimum time (seconds) after onset before sampling negatives"},{"location":"task-reference/#csv-format_2","title":"CSV Format","text":"<p>Expected columns: - <code>sentence_onset</code>: Sentence start time in seconds - <code>sentence_offset</code>: Sentence end time in seconds</p>"},{"location":"task-reference/#negative-sampling-strategy","title":"Negative Sampling Strategy","text":"<p>For each sentence: 1. Sample negatives between <code>onset + negative_margin_s</code> and <code>offset - window_width</code> 2. This ensures negatives don't overlap with the actual onset window 3. Uses <code>window_width</code> from <code>data_params</code> to avoid sampling too close to sentence end</p>"},{"location":"task-reference/#example-config_4","title":"Example Config","text":"<pre><code>data_params:\n  task_name: sentence_onset_task\n  window_width: 0.625  # Used for negative sampling\n  task_params:\n    sentence_csv_path: \"processed_data/all_sentences_podcast.csv\"\n    negatives_per_positive: 2\n    negative_margin_s: 2.0\n</code></pre>"},{"location":"task-reference/#gpt_surprise_task","title":"gpt_surprise_task","text":"<p>File: <code>tasks/gpt_surprise.py</code></p> <p>Description: Regression task predicting GPT-2 XL surprise values (negative log probability) for each word.</p> <p>Task Type: Regression (continuous targets)</p> <p>Output: - <code>start</code>: Word onset time in seconds - <code>target</code>: GPT-2 XL surprise value (higher = more surprising/unpredictable)</p>"},{"location":"task-reference/#configuration-parameters_5","title":"Configuration Parameters","text":"Parameter Type Default Description <code>content_noncontent_path</code> string <code>\"processed_data/df_word_onset_with_pos_class.csv\"</code> Path to CSV with word annotations (relative to cwd or absolute)"},{"location":"task-reference/#csv-format_3","title":"CSV Format","text":"<p>Expected columns: - <code>onset</code>: Word onset time in seconds - <code>surprise</code>: GPT-2 XL surprise value</p>"},{"location":"task-reference/#example-config_5","title":"Example Config","text":"<pre><code>data_params:\n  task_name: gpt_surprise_task\n  task_params:\n    content_noncontent_path: \"processed_data/df_word_onset_with_pos_class.csv\"\n</code></pre>"},{"location":"task-reference/#gpt_surprise_multiclass_task","title":"gpt_surprise_multiclass_task","text":"<p>File: <code>tasks/gpt_surprise.py</code></p> <p>Description: Multi-class classification of GPT-2 XL surprise levels. Surprise values are binned based on mean and standard deviation.</p> <p>Task Type: Multi-class classification (3 classes)</p> <p>Classes: - <code>0</code>: Low surprise (&lt; mean - std) - <code>1</code>: Medium surprise (within std of mean) - <code>2</code>: High surprise (&gt; mean + std)</p> <p>Output: - <code>start</code>: Word onset time in seconds - <code>target</code>: Class label (0-2)</p>"},{"location":"task-reference/#configuration-parameters_6","title":"Configuration Parameters","text":"Parameter Type Default Description <code>content_noncontent_path</code> string <code>\"processed_data/df_word_onset_with_pos_class.csv\"</code> Path to CSV with word annotations (relative to cwd or absolute)"},{"location":"task-reference/#csv-format_4","title":"CSV Format","text":"<p>Expected columns: - <code>onset</code>: Word onset time in seconds - <code>surprise_class</code>: Integer class label (0-2)</p>"},{"location":"task-reference/#example-config_6","title":"Example Config","text":"<pre><code>data_params:\n  task_name: gpt_surprise_multiclass_task\n  task_params:\n    content_noncontent_path: \"processed_data/df_word_onset_with_pos_class.csv\"\n</code></pre>"},{"location":"task-reference/#placeholder_task","title":"placeholder_task","text":"<p>File: <code>tasks/placeholder_task.py</code></p> <p>Description: Minimal example task for testing. Returns constant targets (always 1.0).</p> <p>Task Type: Regression (trivial)</p> <p>Output: - <code>start</code>: Word start time in seconds - <code>target</code>: <code>1.0</code> (constant)</p>"},{"location":"task-reference/#configuration-parameters_7","title":"Configuration Parameters","text":"<p>None. This task takes no parameters.</p>"},{"location":"task-reference/#purpose","title":"Purpose","text":"<p>This is a template showing the minimum requirements for a task: 1. Register with <code>@registry.register_task_data_getter()</code> 2. Accept <code>data_params: DataParams</code> argument 3. Return DataFrame with <code>start</code> and <code>target</code> columns</p> <p>Models will learn to always predict 1.0, making this useful only for testing infrastructure.</p>"},{"location":"task-reference/#example-config_7","title":"Example Config","text":"<pre><code>data_params:\n  task_name: placeholder_task\n</code></pre>"},{"location":"task-reference/#see-also","title":"See Also","text":"<ul> <li>Configuration Guide: Full configuration reference</li> <li>Adding a Task: Step-by-step guide for implementing tasks</li> <li>API Reference: Detailed API documentation</li> </ul>"}]}