config_setter_name: example_foundation_feature_extraction
task_config:
  task_name: word_embedding_decoding_task
  data_params:
    data_root: data
    word_column: word
    subject_ids:
    - 1
    - 2
    - 3
    preprocessing_fn_name: example_foundation_feature_extraction
    preprocessor_params:
      batch_size: 32
  task_specific_config:
    embedding_type: gpt-2xl
    embedding_layer: 24
    embedding_pca_dim: 50
training_params:
  batch_size: 64
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  early_stopping_patience: 10
  n_folds: 5
  losses:
  - mse
  loss_weights:
  - 1.0
  metrics:
  - cosine_sim
  - nll_embedding
  early_stopping_metric: cosine_sim
  smaller_is_better: false
<<<<<<< HEAD
=======

# Data parameters
data_params:
  data_root: data
  word_column: word
  electrode_file_path: processed_data/all_subject_sig.csv
  embedding_type: gpt-2xl
  embedding_layer: 24
  embedding_pca_dim: 50
  subject_ids: [1, 2, 3]

  # Preprocessing function that extracts frozen features
  preprocessing_fn_name: example_foundation_feature_extraction

  # Preprocessor params (model_dir will be set by config_setter)
  preprocessor_params:
    batch_size: 32  # Batch size for feature extraction

# Trial identifier
>>>>>>> 8e54602540327232ddbfc9ca795b4eab08e17474
trial_name: example_foundation_feature_extraction
model_spec:
  constructor_name: example_foundation_mlp
  params:
    model_dir: example_foundation_model/pretrained_model
    layer_sizes:
    - 128
    - 50
    dropout: 0.1
    use_layer_norm: true
  sub_models: {}
