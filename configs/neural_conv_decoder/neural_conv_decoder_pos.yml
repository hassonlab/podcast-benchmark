config_setter_name: neural_conv
task_config:
  task_name: pos_task
  data_params:
    data_root: data
    electrode_file_path: processed_data/all_subject_sig.csv
    window_width: 0.625
    preprocessing_fn_name: window_average_neural_data
    subject_ids:
    - 9
    preprocessor_params:
      num_average_samples: 8
  task_specific_config:
    pos_path: processed_data/df_word_onset_with_pos_class.csv
training_params:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  # Learning rate scheduler: reduces LR when validation metric plateaus
  use_lr_scheduler: true
  scheduler_params:
    factor: 0.5    # Reduce LR by half when metric plateaus
    patience: 10   # Wait 10 epochs without improvement
    min_lr: 1e-6   # Minimum learning rate
    # mode is automatically set to "max" because smaller_is_better: false
  early_stopping_patience: 100
  n_folds: 5
  min_lag: -1000
  max_lag: 1000
  lag_step_size: 200
  losses:
  - cross_entropy
  metrics:
  - roc_auc_multiclass
  - f1
  - confusion_matrix
  early_stopping_metric: roc_auc_multiclass
  smaller_is_better: false
  logistic_regression_baseline: true
  visualize_fold_distribution: false
trial_name: pos_task_sig_elecs_without_other_classes
model_spec:
  constructor_name: ensemble_pitom_model
  params:
    conv_filters: 128
    dropout: 0.2
    num_models: 10
    embedding_dim: 5
    output_activation: softmax
  sub_models: {}
